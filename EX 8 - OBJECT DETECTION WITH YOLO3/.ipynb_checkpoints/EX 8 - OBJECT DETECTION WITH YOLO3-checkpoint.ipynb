{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c208cffe-b563-486e-b650-fca387247840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import required libraries\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c038a65a-23f1-425f-ab36-c3173fccfc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ YOLOv8 model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load the pretrained YOLOv8 model (nano version for speed)\n",
    "# This auto-downloads weights from Ultralytics Hub\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "print(\"✅ YOLOv8 model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b377483-22af-4f45-abeb-1705a02c1266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa4f92c74144394b34d965ce66cb8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/134k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 C:\\Users\\Anand\\Deep Learning\\Lab Experiments\\EX 8 - OBJECT DETECTION WITH YOLO3\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 99.9ms\n",
      "Speed: 3.3ms preprocess, 99.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "img_path = \"https://ultralytics.com/images/bus.jpg\"\n",
    "results = model(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeff60f9-7ffb-4395-abaf-16c01cf7117d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Results' object has no attribute 'show'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Args:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        path (str): The path to the image file.\n        names (dict): A dictionary of class names.\n        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n\n    Attributes:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        orig_shape (tuple): The original image shape in (height, width) format.\n        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n        masks (Masks, optional): A Masks object containing the detection masks.\n        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n        names (dict): A dictionary of class names.\n        path (str): The path to the image file.\n        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n        speed (dict): A dictionary of preprocess, inference and postprocess speeds in milliseconds per image.\n        _keys (tuple): A tuple of attribute names for non-empty attributes.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6088\\68625935.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Plot results using Ultralytics built-in function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Opens window (in local Python)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"output.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Saves annotated image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dlc\\lib\\site-packages\\ultralytics\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;34m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Results' object has no attribute 'show'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Args:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        path (str): The path to the image file.\n        names (dict): A dictionary of class names.\n        boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.\n        masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.\n        probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.\n        keypoints (List[List[float]], optional): A list of detected keypoints for each object.\n\n    Attributes:\n        orig_img (numpy.ndarray): The original image as a numpy array.\n        orig_shape (tuple): The original image shape in (height, width) format.\n        boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.\n        masks (Masks, optional): A Masks object containing the detection masks.\n        probs (Probs, optional): A Probs object containing probabilities of each class for classification task.\n        names (dict): A dictionary of class names.\n        path (str): The path to the image file.\n        keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.\n        speed (dict): A dictionary of preprocess, inference and postprocess speeds in milliseconds per image.\n        _keys (tuple): A tuple of attribute names for non-empty attributes.\n    "
     ]
    }
   ],
   "source": [
    "# Step 4: Display results\n",
    "for r in results:\n",
    "    # Plot results using Ultralytics built-in function\n",
    "    r.show()   # Opens window (in local Python)\n",
    "    r.save(filename=\"output.jpg\")  # Saves annotated image\n",
    "\n",
    "# OR display inline (for Jupyter/Colab)\n",
    "plt.imshow(cv2.cvtColor(r.plot(), cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292496a7-6cc2-4ef3-8838-4fdde141458b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-dlc]",
   "language": "python",
   "name": "conda-env-.conda-dlc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
