{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfab7f3-afa4-495c-903f-990424c343f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e073b9c-2d0c-4f60-ae65-c479643b9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "OUTPUT_DIR = \"gan_outputs\"\n",
    "SAMPLES_DIR = os.path.join(OUTPUT_DIR, \"samples\")\n",
    "CKPT_DIR = os.path.join(OUTPUT_DIR, \"checkpoints\")\n",
    "os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "LATENT_DIM = 128\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10                  # keep small for lab run\n",
    "LEARNING_RATE = 2e-4\n",
    "BETA_1 = 0.5\n",
    "IMAGE_SHAPE = (28, 28, 1)    # MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c56f545-bc60-4d7b-8cf2-c3ce9c14e75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (60000, 28, 28, 1), Test: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "def preprocess_images(x):\n",
    "    x = x.astype(\"float32\")\n",
    "    x = (x - 127.5) / 127.5  # scale to [-1, 1]\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    return x\n",
    "\n",
    "x_train = preprocess_images(x_train)\n",
    "x_test = preprocess_images(x_test)\n",
    "\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(x_train)\n",
    "    .shuffle(1024, seed=SEED)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(x_test)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "print(f\"Train: {x_train.shape}, Test: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06745a7-cbc0-4abf-9bb6-9c8d9b574100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 12544)             1605632   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 12544)            50176     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 12544)             0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 7, 7, 128)        819200    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 14, 14, 64)       204800    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 1)        1600      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,682,176\n",
      "Trainable params: 2,656,704\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        1664      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator(latent_dim=LATENT_DIM):\n",
    "    inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "    x = tf.keras.layers.Dense(7 * 7 * 256, use_bias=False)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Reshape((7, 7, 256))(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, 5, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, 5, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(1, 5, strides=2, padding=\"same\", use_bias=False, activation=\"tanh\")(x)\n",
    "    return tf.keras.Model(inputs, x, name=\"generator\")\n",
    "\n",
    "def build_discriminator(input_shape=IMAGE_SHAPE):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(64, 5, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(128, 5, strides=2, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return tf.keras.Model(inputs, outputs, name=\"discriminator\")\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "generator.summary()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a1861d-646c-4e97-89e3-31bee4e6a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim=LATENT_DIM):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.d_loss_tracker = tf.keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_tracker = tf.keras.metrics.Mean(name=\"g_loss\")\n",
    "        self.d_acc_tracker = tf.keras.metrics.BinaryAccuracy(name=\"d_acc\", threshold=0.5)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_tracker, self.g_loss_tracker, self.d_acc_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # Train discriminator\n",
    "        z = tf.random.normal((batch_size, self.latent_dim))\n",
    "        fake_images = self.generator(z, training=True)\n",
    "        real_labels = tf.ones((batch_size, 1))\n",
    "        fake_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_real = self.discriminator(real_images, training=True)\n",
    "            pred_fake = self.discriminator(fake_images, training=True)\n",
    "            d_loss = self.loss_fn(real_labels, pred_real) + self.loss_fn(fake_labels, pred_fake)\n",
    "\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Train generator\n",
    "        z = tf.random.normal((batch_size, self.latent_dim))\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated = self.generator(z, training=True)\n",
    "            pred = self.discriminator(generated, training=True)\n",
    "            g_loss = self.loss_fn(misleading_labels, pred)\n",
    "\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Metrics\n",
    "        y_true = tf.concat([tf.ones_like(pred_real), tf.zeros_like(pred_fake)], axis=0)\n",
    "        y_pred = tf.concat([pred_real, pred_fake], axis=0)\n",
    "        self.d_loss_tracker.update_state(d_loss)\n",
    "        self.g_loss_tracker.update_state(g_loss)\n",
    "        self.d_acc_tracker.update_state(y_true, y_pred)\n",
    "\n",
    "        return {\"d_loss\": self.d_loss_tracker.result(),\n",
    "                \"g_loss\": self.g_loss_tracker.result(),\n",
    "                \"d_acc\": self.d_acc_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17611ad5-d8da-49b8-9885-db4f44905fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "opt_d = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
    "opt_g = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
    "\n",
    "gan = GAN(generator, discriminator, latent_dim=LATENT_DIM)\n",
    "gan.compile(d_optimizer=opt_d, g_optimizer=opt_g, loss_fn=bce)\n",
    "\n",
    "# -------------------------\n",
    "# IMAGE GRID UTILS\n",
    "# -------------------------\n",
    "def save_image_grid(images, grid_rows, grid_cols, path):\n",
    "    import cv2\n",
    "    images = (images + 1.0) / 2.0  # [-1,1] → [0,1]\n",
    "    images = np.clip(images, 0, 1)\n",
    "    images = (images * 255).astype(\"uint8\")\n",
    "\n",
    "    H, W = images.shape[1], images.shape[2]\n",
    "    C = images.shape[3]\n",
    "    grid = np.zeros((grid_rows * H, grid_cols * W, C), dtype=np.uint8)\n",
    "\n",
    "    idx = 0\n",
    "    for r in range(grid_rows):\n",
    "        for c in range(grid_cols):\n",
    "            if idx >= images.shape[0]:\n",
    "                break\n",
    "            grid[r*H:(r+1)*H, c*W:(c+1)*W, :] = images[idx]\n",
    "            idx += 1\n",
    "\n",
    "    if C == 1:\n",
    "        cv2.imwrite(path, grid.squeeze(-1))\n",
    "    else:\n",
    "        cv2.imwrite(path, cv2.cvtColor(grid, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "class SampleImagesCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, num_samples=25, rows=5, cols=5, latent_dim=LATENT_DIM):\n",
    "        self.num_samples, self.rows, self.cols, self.latent_dim = num_samples, rows, cols, latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        z = tf.random.normal((self.num_samples, self.latent_dim))\n",
    "        gen = self.model.generator(z, training=False).numpy()\n",
    "        path = os.path.join(SAMPLES_DIR, f\"epoch_{epoch+1:03d}.png\")\n",
    "        save_image_grid(gen, self.rows, self.cols, path)\n",
    "        print(f\"[Saved] {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7a095-e0ce-4a3c-bb06-0c5c6ee4ecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "[Saved] gan_outputs\\samples\\epoch_001.png\n",
      "468/468 - 222s - d_loss: 1.3565 - g_loss: 0.8276 - d_acc: 0.6514 - 222s/epoch - 475ms/step\n",
      "Epoch 2/10\n",
      "[Saved] gan_outputs\\samples\\epoch_002.png\n",
      "468/468 - 230s - d_loss: 1.3607 - g_loss: 0.8033 - d_acc: 0.6383 - 230s/epoch - 492ms/step\n",
      "Epoch 3/10\n",
      "[Saved] gan_outputs\\samples\\epoch_003.png\n",
      "468/468 - 224s - d_loss: 1.3729 - g_loss: 0.7806 - d_acc: 0.6117 - 224s/epoch - 478ms/step\n",
      "Epoch 4/10\n",
      "[Saved] gan_outputs\\samples\\epoch_004.png\n",
      "468/468 - 222s - d_loss: 1.3690 - g_loss: 0.7837 - d_acc: 0.6172 - 222s/epoch - 474ms/step\n",
      "Epoch 5/10\n"
     ]
    }
   ],
   "source": [
    "history = gan.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[SampleImagesCallback()],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645371e3-9b5a-4bf4-bc35-bab5a574e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.random.normal((25, LATENT_DIM))\n",
    "gen_images = generator(z, training=False).numpy()\n",
    "save_image_grid(gen_images, 5, 5, os.path.join(SAMPLES_DIR, \"final.png\"))\n",
    "\n",
    "# Evaluate discriminator accuracy on test set\n",
    "metric = tf.keras.metrics.BinaryAccuracy()\n",
    "for real in test_ds.take(20):  # limit batches\n",
    "    pred = discriminator(real, training=False)\n",
    "    metric.update_state(tf.ones_like(pred), pred)\n",
    "print(f\"Discriminator accuracy on test real: {metric.result().numpy():.4f}\")\n",
    "\n",
    "# Fake accuracy\n",
    "z = tf.random.normal((500, LATENT_DIM))\n",
    "fakes = generator(z, training=False)\n",
    "pred = discriminator(fakes, training=False)\n",
    "metric2 = tf.keras.metrics.BinaryAccuracy()\n",
    "metric2.update_state(tf.zeros_like(pred), pred)\n",
    "print(f\"Discriminator accuracy on generated fakes: {metric2.result().numpy():.4f}\")\n",
    "\n",
    "print(f\"Final D Loss: {history.history['d_loss'][-1]:.4f}\")\n",
    "print(f\"Final G Loss: {history.history['g_loss'][-1]:.4f}\")\n",
    "print(f\"Final D Accuracy (train): {history.history['d_acc'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a51ea2-8a00-40af-8cc4-6c967303d8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-dlc]",
   "language": "python",
   "name": "conda-env-.conda-dlc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
